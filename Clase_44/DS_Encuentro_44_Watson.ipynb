{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Watson\n",
    "\n",
    "Paso 0: Configurar Watson (instalar librerías, armar usuario y conseguir los permisos necesarios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade watson-developer-cloud\n",
    "# !pip install --upgrade watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurando la API de watson\n",
    "En este paso van a precisar usar el api_key que se generan en la página de IBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Eso aparecía a en el notebook que se bajan de la página (ya no funciona):\n",
    "# from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "# from watson_developer_cloud.natural_language_understanding_v1 import Features, EmotionOptions, SentimentOptions\n",
    "\n",
    "# Esta es la nueva forma de hacerlo\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, CategoriesOptions, EmotionOptions, SentimentOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2019-07-12',\n",
    "    iam_apikey='Insertar_Su_Key',\n",
    "    url='https://gateway-syd.watsonplatform.net/natural-language-understanding/api'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando a Watson\n",
    "\n",
    "Exploremos el tipo de objeto que nos devuelve Watson y como funciona para distintas frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto objetivo\n",
    "text = 'This is a very silly text, it drives me crazy when I read it.'\n",
    "\n",
    "# Importamos el modelo que vamos a usar y le avisamos que features queremo que devuelva\n",
    "# y en que lenguaje está el texto (esto es mejor que dejarlo adivinar)\n",
    "response = natural_language_understanding.analyze(text=text,features=Features(emotion=EmotionOptions(), sentiment=SentimentOptions()),language='en')\n",
    "resultado = response.result\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tomar sólo alguno de los resultados, podemos acceder al diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultado['sentiment']['document']['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos ahora un texto en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto objetivo\n",
    "text = 'Este texto no tiene ningún objetivo, vive en la soledad que genera saber que su existencia no tiene un proposito determinado.'\n",
    "\n",
    "# Importamos el modelo que vamos a usar y le avisamos que features queremo que devuelva\n",
    "# y en que lenguaje está el texto (esto es mejor que dejarlo adivinar)\n",
    "response = natural_language_understanding.analyze(text=text,features=Features(emotion=EmotionOptions(), sentiment=SentimentOptions()),language='es')\n",
    "resultado = response.result\n",
    "resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset de películas\n",
    "Este es el dataset propuesto por la plataforma de Acámica, al estár en ingles permite explotar todas las funcionalidades de Watson. Carguen distintos reviews y comprueben si la devolución del analisis de emosiones de Watson coinciden con lo que perciben del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "moviedir = r'./dataset/movie_reviews' \n",
    "movie_reviews = load_files(moviedir, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analisis_watson(movie_reviews.data[4]))\n",
    "print(movie_reviews.target[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset de Noticias Infobae de hoy\n",
    "\n",
    "Este dataset se lo preparamos para que puedan explorar cómo funciona Watson en textos en español. Algunas de las funcionalidades se pierden (no reporta las emociones), pero sí clasifica como positivo o negativo los cuerpos de texto. Noten que otra estrategia podría ser traducir el texto y luego aplicarle el algoritmo de Watson en inglés. Esta otra estrategia no siempre funciona bien, depende mucho de la calidad de la traducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = '2019_08_21.feather'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploremos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiero ver el sentimiento de los cuerpos de la noticia.\n",
    "noticias_hoy = pd.read_feather(nombre_archivo)\n",
    "noticias_hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuerpos = noticias_hoy.Texto\n",
    "titulos = noticias_hoy.Titulo\n",
    "print(len(cuerpos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular el sentimiento para cada una de las noticias y agregarlo al dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cuerpos = []\n",
    "\n",
    "for este_texto in cuerpos:\n",
    "    \n",
    "    # Quitamos del texto este símbolo que indica final de parrafo\n",
    "    este_texto = este_texto.replace('\\n','')\n",
    "    \n",
    "    # Analisis sentimiento del cuerpo\n",
    "    # Le pedimos solo el sentimiento, y le avisamos que está en español\n",
    "    response = natural_language_understanding.analyze(text=este_texto,features=Features(sentiment=SentimentOptions()),language='es')\n",
    "    resultado = response.result\n",
    "    score_cuerpos.append(resultado['sentiment']['document']['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_cuerpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente agregamos la columna al dataset\n",
    "noticias_hoy['Sentimiento'] = score_cuerpos\n",
    "noticias_hoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploremos un poco los resultados. Veamos el promedio de sentimiento de todas las noticias (esto nos va a dar una idea del ánimo general del día). Luego busquemos la noticia más positiva y la más negativa, para ver si coincidimos con el criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_los_valores = noticias_hoy['Sentimiento']\n",
    "animo_general = np.mean(todos_los_valores)\n",
    "print(animo_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticia_positiva = noticias_hoy.loc[noticias_hoy['Sentimiento'].idxmax()]\n",
    "print(noticia_positiva.Titulo)\n",
    "print(noticia_positiva.Sentimiento)\n",
    "#print(noticia_positiva.Subtitulo)\n",
    "print(noticia_positiva.Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticia_negativa = noticias_hoy.loc[noticias_hoy['Sentimiento'].idxmin()]\n",
    "print(noticia_negativa.Titulo)\n",
    "print(noticia_negativa.Sentimiento)\n",
    "#print(noticia_negativa.Subtitulo)\n",
    "#print(noticia_negativa.Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
